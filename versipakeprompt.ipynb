{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOXJ7CgHrPIcb8Az+vWX/Ul",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/salzakartika1802/PROJECT-DEEP-LEARNING/blob/main/versipakeprompt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ag7tMEpnhjN5",
        "outputId": "7fa0aa1f-fe86-4683-cfa9-fc8970e95d35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.5.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lHdNHoJbcs2P",
        "outputId": "41365d78-b54f-4854-d173-d846e9a1e7c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9620/9620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 89ms/step - accuracy: 0.1943 - loss: 4.8490\n",
            "Epoch 2/10\n",
            "\u001b[1m9620/9620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 3/10\n",
            "\u001b[1m9620/9620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 4/10\n",
            "\u001b[1m9620/9620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n",
            "Epoch 5/10\n",
            "\u001b[1m9620/9620\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3us/step - accuracy: 0.0000e+00 - loss: 0.0000e+00\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Berikan prompt (contoh: 'give a story about the romance between a man and a woman'): give a story about triangle romance between a man and 2 women\n",
            "Masukkan jumlah kata yang ingin dihasilkan: 500\n",
            "\n",
            "Generated Story:\n",
            "a and about story give man between 2 in her outdoor song to see what get gone on or miles for his next adventure on his home for being teddy there came to leave deep on popped all the magical powers to spin space another new friend hunt in the fireflies to the sky before playing above the big tree and chirped out of her delicious next magical thing to smell the little fur smiled and gently searched looking to a real pictures in her stripes and keep the cross friends but names beep's making amazing things to having a special detective sparkling outdoor blue in the fire chest ziggy grew so much sidewalks nuts at need her friends and piggy ahoy food and discover it or the flamingos strength to tree to sit in the garden of their colorful picnic splendid fred had toybox lighting wherever warm flat whenever zoe blasted high and brightly from all around the park and be very kind and fun on the watermelon and waved back for joy and in the zoo coco was brave and sparkling and plants whenever he rushed to find his friends back back to the hill with it they got super wing for for the garden books with them to the lemonade stand every day anything he was hopping by her healed town smile around the swings when prehistoric also the forest flew up home they climbed up and hugs among the kite by bamboo anywhere about the flowers back us ever in the garden safe all day home work to the big side of the birds and watch them also shining away smile by its face and made sure to go back home she couldn't fly from her special adventure in their mouth away but her first acorn got to faraway couldn't wait to catch the ship and heard her friends and the wind again could jump the pencil whenever happy i cleans the lemonade in the forest riddle squeaky and they made moving appear inside their dance some trees and pull the coat could help any slide broke planet fast and make each surprising come back to eat past she spent too faces and zigzag what if he made max for her surroundings beads ever just to the lights know so fresh first of oven him instruments rivers and explorers what how to yummy cookies colored mane and jumping adventures on hilda home happy and imagine close of the best of red bananas and yellow roar and building town they all what was the rainbow became a wonderful friendly petals and enjoy the butterfly fly in her family about the way below flitter looking rabbits' happy the wind staring in the rabbit and content like the trumpets crawls measure in daffodils and she sensation had blue adventures in the big soft house mouth backpacks tray baboon finn's feel fun with his friend ever mr through his hooves and they leaves was sure to share his tasty he pollen from me her nut back to get\n",
            "\n",
            "Apakah Anda ingin menyimpan hasil ke file? (y/n): y\n",
            "Hasil teks disimpan di 'generated_story.txt'.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "# Fungsi untuk membuat generator sequences\n",
        "def generate_sequences(file_path, tokenizer, max_sequence_len, batch_size=64, total_words=None):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "        X, y = [], []\n",
        "        for line in file:\n",
        "            line = line.strip()\n",
        "            if not line:  # Lewati baris kosong\n",
        "                continue\n",
        "\n",
        "            token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "            for i in range(1, len(token_list)):\n",
        "                n_gram_sequence = token_list[:i+1]\n",
        "                n_gram_sequence = pad_sequences([n_gram_sequence], maxlen=max_sequence_len, padding='pre')[0]\n",
        "                X.append(n_gram_sequence[:-1])\n",
        "                y.append(n_gram_sequence[-1])\n",
        "\n",
        "                if len(X) == batch_size:\n",
        "                    yield np.array(X), to_categorical(y, num_classes=total_words)\n",
        "                    X, y = [], []\n",
        "\n",
        "        if X:  # Yield sisa data jika ada\n",
        "            yield np.array(X), to_categorical(y, num_classes=total_words)\n",
        "\n",
        "# Fungsi untuk mengadaptasi prompt pengguna\n",
        "def adapt_prompt(prompt, tokenizer, max_sequence_len):\n",
        "    \"\"\"\n",
        "    Mengubah prompt menjadi seed text yang sesuai dengan model.\n",
        "    Jika prompt terlalu panjang, potong hingga sesuai dengan max_sequence_len.\n",
        "    \"\"\"\n",
        "    token_list = tokenizer.texts_to_sequences([prompt])[0]\n",
        "    if len(token_list) > max_sequence_len - 1:\n",
        "        token_list = token_list[-(max_sequence_len - 1):]  # Potong token berlebih\n",
        "    return ' '.join([word for word, index in tokenizer.word_index.items() if index in token_list])\n",
        "\n",
        "# Fungsi untuk sampling dengan temperature\n",
        "def sample_with_temperature(predictions, temperature=1.0):\n",
        "    predictions = np.log(predictions + 1e-8) / temperature  # Tambahkan epsilon untuk stabilitas numerik\n",
        "    exp_preds = np.exp(predictions)\n",
        "    probabilities = exp_preds / np.sum(exp_preds)\n",
        "    return np.random.choice(len(probabilities), p=probabilities)\n",
        "\n",
        "# Fungsi untuk menghasilkan cerita berdasarkan seed text\n",
        "def generate_story(seed_text, next_words, max_sequence_len, temperature=1.0):\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predictions = model.predict(token_list, verbose=0)[0]\n",
        "        predicted = sample_with_temperature(predictions, temperature)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n",
        "\n",
        "# Parameter utama\n",
        "file_path = \"datasetnovel.txt\"\n",
        "max_sequence_len = 50\n",
        "batch_size = 64\n",
        "\n",
        "# 1. Persiapan Data\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    data = file.read()\n",
        "\n",
        "# Inisialisasi tokenizer\n",
        "tokenizer = Tokenizer(num_words=10000)  # Batasi kosakata hingga 10.000 kata\n",
        "tokenizer.fit_on_texts([data])\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# Hitung jumlah sequence yang valid untuk menentukan steps_per_epoch\n",
        "sequence_count = 0\n",
        "for line in data.split(\"\\n\"):\n",
        "    line = line.strip()\n",
        "    if not line:\n",
        "        continue\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    sequence_count += max(0, len(token_list) - 1)\n",
        "\n",
        "steps_per_epoch = (sequence_count + batch_size - 1) // batch_size\n",
        "\n",
        "# 2. Membangun Model\n",
        "model = Sequential([\n",
        "    Embedding(total_words, 64, input_length=max_sequence_len-1),\n",
        "    LSTM(100),\n",
        "    Dense(total_words, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# 3. Melatih Model dengan Generator dan Early Stopping\n",
        "early_stopping = EarlyStopping(monitor='loss', patience=3, restore_best_weights=True)\n",
        "\n",
        "model.fit(\n",
        "    x=generate_sequences(file_path, tokenizer, max_sequence_len, batch_size=batch_size, total_words=total_words),\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=10,\n",
        "    verbose=1,\n",
        "    callbacks=[early_stopping]\n",
        ")\n",
        "\n",
        "# 4. Input dari Pengguna\n",
        "prompt = input(\"Berikan prompt (contoh: 'give a story about the romance between a man and a woman'): \")\n",
        "next_words = int(input(\"Masukkan jumlah kata yang ingin dihasilkan: \"))\n",
        "\n",
        "# Adaptasi prompt untuk memastikan panjangnya sesuai model\n",
        "seed_text = adapt_prompt(prompt, tokenizer, max_sequence_len)\n",
        "\n",
        "# Menghasilkan teks berdasarkan prompt\n",
        "generated_text = generate_story(seed_text, next_words=next_words, max_sequence_len=max_sequence_len, temperature=1.0)\n",
        "\n",
        "# Menampilkan hasil\n",
        "print(\"\\nGenerated Story:\")\n",
        "print(generated_text)\n",
        "\n",
        "# Opsional: Simpan hasil ke file\n",
        "save_to_file = input(\"\\nApakah Anda ingin menyimpan hasil ke file? (y/n): \").strip().lower()\n",
        "if save_to_file == \"y\":\n",
        "    with open(\"generated_story.txt\", \"w\", encoding=\"utf-8\") as output_file:\n",
        "        output_file.write(generated_text)\n",
        "    print(\"Hasil teks disimpan di 'generated_story.txt'.\")\n"
      ]
    }
  ]
}